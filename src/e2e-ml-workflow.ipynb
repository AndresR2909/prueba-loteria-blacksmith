{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Create production ML pipelines with Python SDK v2\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "- connect to your Azure ML workspace\n",
        "- create Azure ML data assets\n",
        "- create reusable Azure ML components\n",
        "- create, validate and run Azure ML pipelines\n",
        "- deploy the newly-trained model as an endpoint\n",
        "- call the Azure ML endpoint for inferencing"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Requirements** - In order to benefit from this tutorial, you need to have:\n",
        "- basic understanding of Machine Learning projects workflow\n",
        "- an Azure subscription. If you don't have an Azure subscription, [create a free account](https://aka.ms/AMLFree) before you begin.\n",
        "- a working Azure ML workspace. A workspace can be created via Azure Portal, Azure CLI, or Python SDK. [Read more](https://docs.microsoft.com/en-us/azure/machine-learning/how-to-manage-workspace?tabs=python).\n",
        "- a Python environmnet\n",
        "- [installed Azure Machine Learning Python SDK v2](https://github.com/Azure/azureml-examples/blob/sdk-preview/sdk/setup.sh)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "```\n",
        "prueba-loteria-blacksmith \n",
        "    src\n",
        "        data_prep\n",
        "            data_prep.py \n",
        "        train\n",
        "            train.py\n",
        "            train.yml   \n",
        "        dependencies\n",
        "            conda.yaml\n",
        "        deploy\n",
        "            sample-request.json\n",
        "        local\n",
        "            eda.ipynb\n",
        "            train.ipynb\n",
        "        e2e-ml-workflow.ipynb\n",
        "```\n",
        "\n",
        "\n",
        "Reference for more available credentials if it does not work for you:,[azure-identity reference doc](https://docs.microsoft.com/en-us/python/api/azure-identity/azure.identity?view=azure-python)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "attributes": {
          "classes": [
            "Python"
          ],
          "id": ""
        },
        "name": "import-mlclient"
      },
      "outputs": [],
      "source": [
        "# Handle to the workspace\n",
        "from azure.ai.ml import MLClient\n",
        "\n",
        "# Authentication package\n",
        "from azure.identity import DefaultAzureCredential, InteractiveBrowserCredential\n",
        "\n",
        "try:\n",
        "    credential = DefaultAzureCredential()\n",
        "    # Check if given credential can get token successfully.\n",
        "    credential.get_token(\"https://management.azure.com/.default\")\n",
        "except Exception as ex:\n",
        "    # Fall back to InteractiveBrowserCredential in case DefaultAzureCredential not work\n",
        "    credential = InteractiveBrowserCredential()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In the next cell, enter your Subscription ID, Resource Group name and Workspace name. To find your Subscription ID:\n",
        "1. In the upper right Azure Machine Learning Studio toolbar, select your workspace name.\n",
        "1. At the bottom, select **View all properties in Azure Portal**\n",
        "1. Copy the value from Azure Portal into the code."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "attributes": {
          "classes": [
            "Python"
          ],
          "id": ""
        },
        "name": "ml_client"
      },
      "outputs": [],
      "source": [
        "# Get a handle to the workspace\n",
        "ml_client = MLClient(\n",
        "    credential=credential,\n",
        "    subscription_id='dc213d49-9972-4e9e-a634-246cefdc8655',\n",
        "    resource_group_name='rg-test-loteriablacksmith',\n",
        "    workspace_name='aml-test-loteriablacksmith',\n",
        ")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Register data from local machine\n",
        "\n",
        "Azure ML uses a [`Data`](https://docs.microsoft.com/azure/machine-learning/how-to-create-register-data-assets?tabs=Python-SDK) object to register a reusable definition of data, and consume data within a pipeline."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'c:\\\\repos\\\\prueba-loteria-blacksmith\\\\src'"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os\n",
        "os.getcwd()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "name": "credit_data"
      },
      "outputs": [],
      "source": [
        "from azure.ai.ml.entities import Data\n",
        "from azure.ai.ml.constants import AssetTypes\n",
        "\n",
        "local_path = \"data/Txs_LoteriaBlacksmith.xlsx\"\n",
        "\n",
        "historical_data = Data(\n",
        "    name=\"ds_loteria_blacksmith\",\n",
        "    path=local_path,\n",
        "    type=AssetTypes.URI_FILE,\n",
        "    description=\"Dataset de historicos de ventas de loteria de Blacksmith\",\n",
        "    tags={\"source_type\": \"local\", \"source\": \"unknown\"},\n",
        "    version=\"1.0.0\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "attributes": {
          "classes": [
            "Python"
          ],
          "id": ""
        },
        "name": "update-credit_data"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32mUploading Txs_LoteriaBlacksmith.xlsx\u001b[32m (< 1 MB): 100%|##########| 5.72M/5.72M [00:12<00:00, 448kB/s]\n",
            "\u001b[39m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset with name ds_loteria_blacksmith was registered to workspace, the dataset version is 1.0.0\n"
          ]
        }
      ],
      "source": [
        "credit_data = ml_client.data.create_or_update(historical_data)\n",
        "print(\n",
        "    f\"Dataset with name {credit_data.name} was registered to workspace, the dataset version is {credit_data.version}\"\n",
        ")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create a job environment for pipeline steps\n",
        "\n",
        "create a conda environment for your jobs, using a conda yaml file."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The specification contains some usual packages, that you'll use in your pipeline (numpy, pip).\n",
        "\n",
        "\n",
        "Use the *yaml* file to create and register this custom environment in your workspace:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "attributes": {
          "classes": [
            "Python"
          ],
          "id": ""
        },
        "name": "custom_env_name"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Environment with name aml-test-blacksmith is registered to workspace, the environment version is 0.1.0\n"
          ]
        }
      ],
      "source": [
        "from azure.ai.ml.entities import Environment\n",
        "\n",
        "custom_env_name = \"aml-test-blacksmith\"\n",
        "\n",
        "pipeline_job_env = Environment(\n",
        "    name=custom_env_name,\n",
        "    description=\"Custom environment for lotery blacksmith forecasting pipeline\",\n",
        "    tags={\"libraries\": \"scikit-learn,pmdarima,skforecast,xgboost\"},\n",
        "    conda_file=os.path.join('conda_env', \"conda.yml\"),\n",
        "    image=\"mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04:latest\",\n",
        "    version=\"0.1.0\",\n",
        ")\n",
        "pipeline_job_env = ml_client.environments.create_or_update(pipeline_job_env)\n",
        "\n",
        "print(\n",
        "    f\"Environment with name {pipeline_job_env.name} is registered to workspace, the environment version is {pipeline_job_env.version}\"\n",
        ")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Build the training pipeline\n",
        "\n",
        "## Create component 1: data prep (using yaml definition)\n",
        "first component. This component handles the preprocessing of the data. The preprocessing task is performed in the *data_prep.py* python file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "name": "data_prep_component"
      },
      "outputs": [],
      "source": [
        "from azure.ai.ml import command\n",
        "from azure.ai.ml import Input, Output\n",
        "\n",
        "# importing the Component Package\n",
        "from azure.ai.ml import load_component\n",
        "dir = 'c:/repos/prueba-loteria-blacksmith/src/data_preprocess/'\n",
        "\n",
        "# Loading the component from the yml file\n",
        "data_prep_component = load_component(source=os.path.join(dir, \"data_prep.yml\"))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32mUploading data_preprocess (0.01 MBs): 100%|##########| 8275/8275 [00:00<00:00, 9146.81it/s]\n",
            "\u001b[39m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Component data_prep_lotery_blacksmith with Version 1 is registered\n"
          ]
        }
      ],
      "source": [
        "# Now we register the component to the workspace\n",
        "data_prep_component = ml_client.create_or_update(data_prep_component)\n",
        "\n",
        "# Create (register) the component in your workspace\n",
        "print(\n",
        "    f\"Component {data_prep_component.name} with Version {data_prep_component.version} is registered\"\n",
        ")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create component 2: training (using yaml definition)\n",
        "\n",
        "The second component that you'll create will consume the training and test data, train and select a model and return the output model and the predictions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "attributes": {
          "classes": [
            "Python"
          ],
          "id": ""
        },
        "name": "train_component"
      },
      "outputs": [],
      "source": [
        "# importing the Component Package\n",
        "from azure.ai.ml import load_component\n",
        "\n",
        "# Loading the component from the yml file\n",
        "train_component = load_component(source=os.path.join(\"train\", \"train.yml\"))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now create and register the component:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "attributes": {
          "classes": [
            "Python"
          ],
          "id": ""
        },
        "name": "update-train_component"
      },
      "outputs": [],
      "source": [
        "# Now we register the component to the workspace\n",
        "train_component = ml_client.create_or_update(train_component)\n",
        "\n",
        "# Create (register) the component in your workspace\n",
        "print(\n",
        "    f\"Component {train_component.name} with Version {train_component.version} is registered\"\n",
        ")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create the pipeline from components"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Here, you'll use *input data*, *split ratio* and *registered model name* as input variables. Then call the components and connect them via their inputs /outputs identifiers. The outputs of each step can be accessed via the `.outputs` property."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "attributes": {
          "classes": [
            "Python"
          ],
          "id": ""
        }
      },
      "source": [
        "The python functions returned by `load_component()` work as any regular python function that we'll use within a pipeline to call each step.\n",
        "\n",
        "To code the pipeline, we use a specific `@dsl.pipeline` decorator that identifies the Azure ML pipelines. In the decorator, we can specify the pipeline description and default resources like compute (serverless is used here) and storage. Like a python function, pipelines can have inputs, you can then create multiple instances of a single pipeline with different inputs.\n",
        "\n",
        "Here, we used *input data*, *split ratio* and *registered model name* as input variables. We then call the components and connect them via their inputs /outputs identifiers. The outputs of each step can be accessed via the `.outputs` property."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "attributes": {
          "classes": [
            "Python"
          ],
          "id": ""
        },
        "name": "pipeline"
      },
      "outputs": [],
      "source": [
        "# the dsl decorator tells the sdk that we are defining an Azure ML pipeline\n",
        "from azure.ai.ml import dsl, Input, Output\n",
        "\n",
        "\n",
        "@dsl.pipeline(\n",
        "    compute=\"serverless\",\n",
        "    description=\"E2E data_perp-train pipeline\",\n",
        ")\n",
        "def credit_defaults_pipeline(\n",
        "    pipeline_job_data_input,\n",
        "    pipeline_job_test_train_ratio,\n",
        "    pipeline_job_learning_rate,\n",
        "    pipeline_job_registered_model_name,\n",
        "):\n",
        "    # using data_prep_function like a python call with its own inputs\n",
        "    data_prep_job = data_prep_component(\n",
        "        data=pipeline_job_data_input,\n",
        "        test_train_ratio=pipeline_job_test_train_ratio,\n",
        "    )\n",
        "\n",
        "    # using train_func like a python call with its own inputs\n",
        "    train_job = train_component(\n",
        "        train_data=data_prep_job.outputs.train_data,  # note: using outputs from previous step\n",
        "        test_data=data_prep_job.outputs.test_data,  # note: using outputs from previous step\n",
        "        learning_rate=pipeline_job_learning_rate,  # note: using a pipeline input as parameter\n",
        "        registered_model_name=pipeline_job_registered_model_name,\n",
        "    )\n",
        "\n",
        "    # a pipeline returns a dictionary of outputs\n",
        "    # keys will code for the pipeline output identifier\n",
        "    return {\n",
        "        \"pipeline_job_train_data\": data_prep_job.outputs.train_data,\n",
        "        \"pipeline_job_test_data\": data_prep_job.outputs.test_data,\n",
        "    }"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now use your pipeline definition to instantiate a pipeline with your dataset, split rate of choice and the name you picked for your model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "attributes": {
          "classes": [
            "Python"
          ],
          "id": ""
        },
        "name": "registered_model_name"
      },
      "outputs": [],
      "source": [
        "registered_model_name = \"credit_defaults_model\"\n",
        "\n",
        "# Let's instantiate the pipeline with the parameters of our choice\n",
        "pipeline = credit_defaults_pipeline(\n",
        "    pipeline_job_data_input=Input(type=\"uri_file\", path=credit_data.path),\n",
        "    pipeline_job_test_train_ratio=0.25,\n",
        "    pipeline_job_learning_rate=0.05,\n",
        "    pipeline_job_registered_model_name=registered_model_name,\n",
        ")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Submit the job \n",
        "\n",
        "It's now time to submit the job to run in Azure ML. This time you'll use `create_or_update`  on `ml_client.jobs`.\n",
        "\n",
        "Here you'll also pass an experiment name. An experiment is a container for all the iterations one does on a certain project. All the jobs submitted under the same experiment name would be listed next to each other in Azure ML studio.\n",
        "\n",
        "Once completed, the pipeline will register a model in your workspace as a result of training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "name": "returned_job"
      },
      "outputs": [],
      "source": [
        "import webbrowser\n",
        "\n",
        "# submit the pipeline job\n",
        "pipeline_job = ml_client.jobs.create_or_update(\n",
        "    pipeline,\n",
        "    # Project's name\n",
        "    experiment_name=\"e2e_registered_components\",\n",
        ")\n",
        "# open the pipeline in web browser\n",
        "webbrowser.open(pipeline_job.studio_url)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "You can track the progress of your pipeline, by using the link generated in the cell above or in this notebook using the following code:\n",
        "```python\n",
        "    ml_client.jobs.stream(pipeline_job.name)\n",
        "```\n",
        "\n",
        "When you select on each component, you'll see more information about the results of that component. \n",
        "There are two important parts to look for at this stage:\n",
        "* `Outputs+logs` > `user_logs` > `std_log.txt`\n",
        "This section shows the script run sdtout."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* `Outputs+logs` > `Metric`\n",
        "This section shows different logged metrics. In this example. mlflow `autologging`, has automatically logged the training metrics."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Deploy the model as an online endpoint\n",
        "\n",
        "Now deploy your machine learning model as a web service in the Azure cloud, an [`online endpoint`](https://docs.microsoft.com/azure/machine-learning/concept-endpoints).\n",
        "\n",
        "To deploy a machine learning service, you usually need:\n",
        "\n",
        "* The model assets (filed, metadata) that you want to deploy. You've already registered these assets in your training component.\n",
        "* Some code to run as a service. The code executes the model on a given input request. This entry script receives data submitted to a deployed web service and passes it to the model, then returns the model's response to the client. The script is specific to your model. The entry script must understand the data that the model expects and returns. When using a MLFlow model, as in this tutorial, this script is automatically created for you. Samples of scoring scripts can be found [here](https://github.com/Azure/azureml-examples/tree/sdk-preview/sdk/endpoints/online).\n",
        "\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create a new online endpoint\n",
        "\n",
        "Now that you have a registered model and an inference script, it's time to create your online endpoint. The endpoint name needs to be unique in the entire Azure region. For this tutorial, you'll create a unique name using [`UUID`](https://en.wikipedia.org/wiki/Universally_unique_identifier#:~:text=A%20universally%20unique%20identifier%20(UUID,%2C%20for%20practical%20purposes%2C%20unique.)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "attributes": {
          "classes": [
            "Python"
          ],
          "id": ""
        },
        "name": "online_endpoint_name"
      },
      "outputs": [],
      "source": [
        "import uuid\n",
        "\n",
        "# Creating a unique name for the endpoint\n",
        "online_endpoint_name = \"credit-endpoint-\" + str(uuid.uuid4())[:8]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "attributes": {
          "classes": [
            "Python"
          ],
          "id": ""
        },
        "name": "endpoint"
      },
      "outputs": [],
      "source": [
        "from azure.ai.ml.entities import (\n",
        "    ManagedOnlineEndpoint,\n",
        "    ManagedOnlineDeployment,\n",
        "    Model,\n",
        "    Environment,\n",
        ")\n",
        "\n",
        "# create an online endpoint\n",
        "endpoint = ManagedOnlineEndpoint(\n",
        "    name=online_endpoint_name,\n",
        "    description=\"this is an online endpoint\",\n",
        "    auth_mode=\"key\",\n",
        "    tags={\n",
        "        \"training_dataset\": \"credit_defaults\",\n",
        "        \"model_type\": \"sklearn.GradientBoostingClassifier\",\n",
        "    },\n",
        ")\n",
        "\n",
        "endpoint_result = ml_client.begin_create_or_update(endpoint).result()\n",
        "\n",
        "print(\n",
        "    f\"Endpint {endpoint_result.name} provisioning state: {endpoint_result.provisioning_state}\"\n",
        ")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Once you've created an endpoint, you can retrieve it as below:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "attributes": {
          "classes": [
            "Python"
          ],
          "id": ""
        },
        "name": "update-endpoint"
      },
      "outputs": [],
      "source": [
        "endpoint = ml_client.online_endpoints.get(name=online_endpoint_name)\n",
        "\n",
        "print(\n",
        "    f'Endpint \"{endpoint.name}\" with provisioning state \"{endpoint.provisioning_state}\" is retrieved'\n",
        ")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Deploy the model to the endpoint\n",
        "\n",
        "Once the endpoint is created, deploy the model with the entry script. Each endpoint can have multiple deployments and direct traffic to these deployments can be specified using rules. Here you'll create a single deployment that handles 100% of the incoming traffic. We have chosen a color name for the deployment, for example, *blue*, *green*, *red* deployments, which is arbitrary.\n",
        "\n",
        "You can check the *Models* page on the Azure ML studio, to identify the latest version of your registered model. Alternatively, the code below will retrieve the latest version number for you to use."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "attributes": {
          "classes": [
            "Python"
          ],
          "id": ""
        },
        "name": "latest_model_version"
      },
      "outputs": [],
      "source": [
        "# Let's pick the latest version of the model\n",
        "latest_model_version = max(\n",
        "    [int(m.version) for m in ml_client.models.list(name=registered_model_name)]\n",
        ")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Deploy the latest version of the model.  \n",
        "\n",
        "> [!NOTE]\n",
        "> Expect this deployment to take approximately 6 to 8 minutes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "name": "model"
      },
      "outputs": [],
      "source": [
        "# picking the model to deploy. Here we use the latest version of our registered model\n",
        "model = ml_client.models.get(name=registered_model_name, version=latest_model_version)\n",
        "\n",
        "\n",
        "# create an online deployment.\n",
        "blue_deployment = ManagedOnlineDeployment(\n",
        "    name=\"blue\",\n",
        "    endpoint_name=online_endpoint_name,\n",
        "    model=model,\n",
        "    instance_type=\"Standard_F4s_v2\",\n",
        "    instance_count=1,\n",
        ")\n",
        "\n",
        "blue_deployment_results = ml_client.online_deployments.begin_create_or_update(\n",
        "    blue_deployment\n",
        ").result()\n",
        "\n",
        "print(\n",
        "    f\"Deployment {blue_deployment_results.name} provisioning state: {blue_deployment_results.provisioning_state}\"\n",
        ")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Test with a sample query\n",
        "\n",
        "Now that the model is deployed to the endpoint, you can run inference with it.\n",
        "\n",
        "Create a sample request file following the design expected in the run method in the score script."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "name": "sample-request.json"
      },
      "outputs": [],
      "source": [
        "deploy_dir = \"./deploy\"\n",
        "os.makedirs(deploy_dir, exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "name": "write-sample-request"
      },
      "outputs": [],
      "source": [
        "%%writefile {deploy_dir}/sample-request.json\n",
        "{\n",
        "  \"input_data\": {\n",
        "    \"columns\": [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22],\n",
        "    \"index\": [0, 1],\n",
        "    \"data\": [\n",
        "            [20000,2,2,1,24,2,2,-1,-1,-2,-2,3913,3102,689,0,0,0,0,689,0,0,0,0],\n",
        "            [10, 9, 8, 7, 6, 5, 4, 3, 2, 1, 10, 9, 8, 7, 6, 5, 4, 3, 2, 1, 10, 9, 8]\n",
        "        ]\n",
        "  }\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "attributes": {
          "classes": [
            "Python"
          ],
          "id": ""
        },
        "name": "ml_client.online_endpoints.invoke"
      },
      "outputs": [],
      "source": [
        "# test the blue deployment with some sample data\n",
        "ml_client.online_endpoints.invoke(\n",
        "    endpoint_name=online_endpoint_name,\n",
        "    request_file=\"./deploy/sample-request.json\",\n",
        "    deployment_name=\"blue\",\n",
        ")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Clean up resources\n",
        "\n",
        "If you're not going to use the endpoint, delete it to stop using the resource.  Make sure no other deployments are using an endpoint before you delete it.\n",
        "\n",
        "\n",
        "> [!NOTE]\n",
        "> Expect this step to take approximately 6 to 8 minutes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "attributes": {
          "classes": [
            "python "
          ],
          "id": ""
        },
        "name": "ml_client.online_endpoints.begin_delete"
      },
      "outputs": [],
      "source": [
        "ml_client.online_endpoints.begin_delete(name=online_endpoint_name)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Next Steps\n",
        "\n",
        "Learn more about [Azure ML logging](https://github.com/Azure/azureml-examples/blob/sdk-preview/notebooks/mlflow/mlflow-v1-comparison.ipynb)."
      ]
    }
  ],
  "metadata": {
    "categories": [
      "SDK v2",
      "tutorials"
    ],
    "celltoolbar": "Edit Metadata",
    "description": {
      "description": "Create production ML pipelines with Python SDK v2 in a Jupyter notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}
